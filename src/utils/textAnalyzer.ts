/**
 * ğŸ“‚ src/utils/textAnalyzer.ts
 * ğŸ¯ textAnalyzer.ts - ç»¼åˆæ–‡æœ¬åˆ†æå·¥å…·åº“
 * 
 * ğŸ“‹ åŠŸèƒ½æ¦‚è¿°:
 * - æä¾›å…¨é¢çš„è‹±è¯­æ–‡æœ¬åˆ†æå’Œå¤„ç†åŠŸèƒ½
 * - å®ç°é«˜çº§æ–‡æœ¬æŒ–æ˜å’Œè¯­è¨€å­¦åˆ†æç®—æ³•
 * - æ”¯æŒå¤šç»´åº¦æ–‡æœ¬è´¨é‡è¯„ä¼°å’Œå¯è¯»æ€§åˆ†æ
 * - é›†æˆæ™ºèƒ½å…³é”®è¯æå–å’Œæƒ…æ„Ÿåˆ†æ
 * - æä¾›é«˜æ€§èƒ½çš„æ–‡æœ¬ç»Ÿè®¡å’Œæ¨¡å¼è¯†åˆ«
 * 
 * ğŸ¯ ä¸»è¦åŠŸèƒ½:
 * - æ™ºèƒ½è¯æ±‡æå–å’Œæ–‡æœ¬åˆ†è¯
 * - å¥å­è¾¹ç•Œæ£€æµ‹å’Œç»“æ„åˆ†æ
 * - æ–‡æœ¬å¤æ‚åº¦å’Œå¯è¯»æ€§è¯„ä¼°
 * - è¯æ±‡æ­é…å’ŒN-gramæå–
 * - å…³é”®è¯è‡ªåŠ¨æå–å’ŒTF-IDFåˆ†æ
 * - ç®€å•æƒ…æ„Ÿåˆ†æå’Œè¯­è°ƒè¯†åˆ«
 * - ç»¼åˆæ–‡æœ¬ç»Ÿè®¡å’Œå…ƒæ•°æ®ç”Ÿæˆ
 * 
 * ğŸ—ï¸ æ¶æ„è®¾è®¡:
 * - å•ä¾‹æ¨¡å¼çš„åˆ†æå™¨ç±»è®¾è®¡
 * - æ¨¡å—åŒ–çš„åˆ†æç®—æ³•ç»„ä»¶
 * - ç¼“å­˜ä¼˜åŒ–çš„æ€§èƒ½ç­–ç•¥
 * - å¯æ‰©å±•çš„è§„åˆ™å¼•æ“
 * - å†…å­˜å‹å¥½çš„æ•°æ®å¤„ç†
 * 
 * ğŸ”— é›†æˆç»„ä»¶:
 * - stemmer: è¯å¹²æå–ç®—æ³•é›†æˆ
 * - wordFrequencyService: è¯é¢‘åˆ†ææœåŠ¡
 * - STOP_WORDS: åœç”¨è¯è¿‡æ»¤ç³»ç»Ÿ
 * 
 * ğŸ“¡ æ¥å£å®šä¹‰:
 * - extractWords: è¯æ±‡æå–åŠŸèƒ½
 * - extractSentences: å¥å­åˆ†æåŠŸèƒ½
 * - analyzeComplexity: å¤æ‚åº¦åˆ†æ
 * - findCollocations: æ­é…è¯å‘ç°
 * - extractNGrams: Nå…ƒè¯­æ³•æå–
 * - extractKeywords: å…³é”®è¯æå–
 * - analyzeSentiment: æƒ…æ„Ÿåˆ†æ
 * 
 * ğŸ¨ ç®—æ³•ç‰¹è‰²:
 * - Fleschå¯è¯»æ€§è¯„åˆ†ç®—æ³•
 * - TF-IDFå…³é”®è¯æå–ç®—æ³•
 * - éŸ³èŠ‚è®¡æ•°å¯å‘å¼ç®—æ³•
 * - æ­é…è¯ç»Ÿè®¡å­¦åˆ†æ
 * - æƒ…æ„Ÿè¯å…¸åŒ¹é…ç®—æ³•
 * 
 * ğŸ›¡ï¸ å®‰å…¨è€ƒè™‘:
 * - è¾“å…¥æ–‡æœ¬éªŒè¯å’Œæ¸…ç†
 * - XSSé˜²æŠ¤çš„å†…å®¹å¤„ç†
 * - å†…å­˜ä½¿ç”¨é™åˆ¶æ§åˆ¶
 * - æ— é™å¾ªç¯é˜²æŠ¤æœºåˆ¶
 * - å¼‚å¸¸çŠ¶æ€æ¢å¤å¤„ç†
 * 
 * âš™ï¸ é…ç½®é€‰é¡¹:
 * - åˆ†ææ·±åº¦ç­‰çº§è°ƒæ•´
 * - åœç”¨è¯åº“è‡ªå®šä¹‰
 * - ç®—æ³•å‚æ•°å¾®è°ƒ
 * - æ€§èƒ½é˜ˆå€¼è®¾ç½®
 * - ç¼“å­˜ç­–ç•¥é…ç½®
 */

import { stemWord, enhancedStem, IRREGULAR_VERBS } from './stemmer'

/**
 * ğŸ“ æ–‡æœ¬å¤„ç†è¾“å‡ºçš„è¯æ±‡ä¿¡æ¯æ¥å£
 * 
 * ğŸ“‹ ä¿¡æ¯ç»“æ„:
 * - word: æ ‡å‡†åŒ–åçš„è¯æ±‡
 * - position: åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®ç´¢å¼•
 * - sentence: æ‰€å±å¥å­ç¼–å·
 * - context: å‘¨å›´ä¸Šä¸‹æ–‡æ–‡æœ¬
 */
interface WordInfo {
  word: string
  position: number
  sentence: number
  context: string
}

/**
 * ğŸ“„ å¥å­åˆ†æç»“æœä¿¡æ¯æ¥å£
 * 
 * ğŸ“‹ ç»“æ„è¯´æ˜:
 * - text: å¥å­åŸå§‹æ–‡æœ¬å†…å®¹
 * - words: å¥å­åŒ…å«çš„è¯æ±‡æ•°ç»„
 * - position: å¥å­åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®
 * - length: å¥å­è¯æ±‡æ•°é‡ç»Ÿè®¡
 */
interface SentenceInfo {
  text: string
  words: string[]
  position: number
  length: number
}

/**
 * ğŸš« è‹±è¯­åœç”¨è¯å®Œæ•´é›†åˆ
 * 
 * ğŸ“‹ è¯æ±‡åˆ†ç±»:
 * - å† è¯: a, an, the
 * - ä»‹è¯: in, on, at, by, for, with, without, to, from, of, about ç­‰
 * - è¿è¯: and, or, but, nor, so, yet, because, although ç­‰
 * - ä»£è¯: i, you, he, she, it, we, they, me, him, her ç­‰
 * - åŠ©åŠ¨è¯: am, is, are, was, were, be, been, being ç­‰
 * - å¸¸ç”¨å‰¯è¯: not, no, yes, very, too, so, just, only ç­‰
 * - æ•°è¯: one, two, three, four, five ç­‰
 * 
 * ğŸ¯ è¿‡æ»¤ç›®çš„:
 * - æé«˜å…³é”®è¯æå–è´¨é‡
 * - çªå‡ºæ–‡æœ¬ä¸»è¦å†…å®¹
 * - å‡å°‘åˆ†æå™ªéŸ³æ•°æ®
 * - ä¼˜åŒ–æœç´¢å’ŒåŒ¹é…ç»“æœ
 * - æå‡ç®—æ³•è¿è¡Œæ•ˆç‡
 */
export const STOP_WORDS = new Set([
  // Articles
  'a', 'an', 'the',
  
  // Prepositions
  'in', 'on', 'at', 'by', 'for', 'with', 'without', 'to', 'from', 'of', 'about',
  'under', 'over', 'through', 'between', 'among', 'during', 'before', 'after',
  'above', 'below', 'up', 'down', 'into', 'onto', 'upon', 'within', 'against',
  
  // Conjunctions
  'and', 'or', 'but', 'nor', 'so', 'yet', 'because', 'although', 'while',
  'since', 'unless', 'until', 'if', 'when', 'where', 'why', 'how',
  
  // Pronouns
  'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',
  'my', 'your', 'his', 'her', 'its', 'our', 'their', 'mine', 'yours', 'ours',
  'this', 'that', 'these', 'those', 'who', 'whom', 'whose', 'which', 'what',
  
  // Auxiliary verbs
  'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
  'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
  'shall', 'should', 'may', 'might', 'can', 'could', 'must',
  
  // Common adverbs
  'not', 'no', 'yes', 'very', 'too', 'so', 'just', 'only', 'also',
  'here', 'there', 'now', 'then', 'today', 'tomorrow', 'yesterday',
  'always', 'never', 'sometimes', 'often', 'usually', 'again',
  
  // Numbers
  'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',
  'first', 'second', 'third', 'last', 'next', 'another', 'other', 'some', 'many',
  'few', 'more', 'most', 'less', 'all', 'any', 'each', 'every', 'both', 'either'
])

/**
 * ğŸ”¤ æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦æ¸…ç†æ­£åˆ™
 * 
 * ğŸ“‹ åŒ¹é…è§„åˆ™:
 * - æ’é™¤å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼ã€æ’‡å·
 * - åŒ…å«æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
 * - åŒ…å«ç‰¹æ®Šç¬¦å·å’Œä¸‹åˆ’çº¿
 * - ç”¨äºæ–‡æœ¬æ ‡å‡†åŒ–é¢„å¤„ç†
 */
const PUNCTUATION = /[^\w\s']|_/g

/**
 * ğŸ”¤ å¤šä½™ç©ºç™½å­—ç¬¦æ ‡å‡†åŒ–æ­£åˆ™
 * 
 * ğŸ“‹ åŒ¹é…è§„åˆ™:
 * - è¿ç»­çš„ç©ºç™½å­—ç¬¦
 * - åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦ã€ç©ºæ ¼
 * - ç”¨äºæ–‡æœ¬æ ¼å¼æ ‡å‡†åŒ–
 */
const EXTRA_WHITESPACE = /\s+/g

/**
 * âœ… æœ‰æ•ˆè¯æ±‡éªŒè¯æ­£åˆ™é›†åˆ
 * 
 * ğŸ“‹ éªŒè¯è§„åˆ™:
 * - VALID_WORD: å­—æ¯å¼€å¤´å’Œç»“å°¾ï¼Œä¸­é—´å¯å«æ’‡å·
 * - CONTRACTION: è‹±è¯­ç¼©å†™å½¢å¼è¯†åˆ«
 * - HYPHENATED: è¿å­—ç¬¦å¤åˆè¯è¯†åˆ«
 */
const VALID_WORD = /^[a-zA-Z][a-zA-Z']*[a-zA-Z]$|^[a-zA-Z]$/
const CONTRACTION = /^(n't|'re|'ve|'ll|'d|'s|'m)$/i
const HYPHENATED = /^[a-zA-Z]+-[a-zA-Z]+$/

/**
 * ğŸ”¬ æ–‡æœ¬åˆ†æå™¨ä¸»ç±»
 * 
 * ğŸ“‹ ç±»è®¾è®¡ç‰¹ç‚¹:
 * - å•ä¾‹æ¨¡å¼ç¡®ä¿ä¸€è‡´æ€§
 * - ç¼“å­˜æœºåˆ¶æå‡æ€§èƒ½
 * - æ¨¡å—åŒ–æ–¹æ³•è®¾è®¡
 * - å¯æ‰©å±•çš„ç®—æ³•æ¶æ„
 * - å†…å­˜å‹å¥½çš„å®ç°
 */
export class TextAnalyzer {
  private cache = new Map<string, any>()

  /**
   * ğŸ“ ä»æ–‡æœ¬ä¸­æå–å’Œæ¸…ç†è¯æ±‡
   * 
   * @param text - è¾“å…¥æ–‡æœ¬å†…å®¹
   * @param options - æå–é€‰é¡¹é…ç½®
   * @returns string[] | WordInfo[] - è¯æ±‡æ•°ç»„æˆ–è¯¦ç»†ä¿¡æ¯æ•°ç»„
   * 
   * ğŸ“‹ æå–æµç¨‹:
   * - æ–‡æœ¬æ¸…ç†å’Œæ ‡å‡†åŒ–
   * - å¥å­è¾¹ç•Œæ£€æµ‹åˆ†å‰²
   * - è¯æ±‡æå–å’ŒéªŒè¯
   * - åœç”¨è¯è¿‡æ»¤å¤„ç†
   * - ä½ç½®ä¿¡æ¯è®°å½•
   * 
   * ğŸ¯ é€‰é¡¹é…ç½®:
   * - includeStopWords: æ˜¯å¦åŒ…å«åœç”¨è¯
   * - minLength: æœ€å°è¯æ±‡é•¿åº¦é™åˆ¶
   * - includePositions: æ˜¯å¦åŒ…å«ä½ç½®ä¿¡æ¯
   * 
   * ğŸ›¡ï¸ è´¨é‡æ§åˆ¶:
   * - è¾“å…¥éªŒè¯å’Œè¾¹ç•Œæ£€æŸ¥
   * - è¯æ±‡æœ‰æ•ˆæ€§éªŒè¯
   * - ç¼©å†™è¯è¿‡æ»¤å¤„ç†
   * - ç¼“å­˜æœºåˆ¶é˜²é‡å¤è®¡ç®—
   * 
   * âš™ï¸ æ€§èƒ½ä¼˜åŒ–:
   * - ç¼“å­˜é”®å€¼ä¼˜åŒ–è®¾è®¡
   * - æ‰¹é‡å¤„ç†ä¼˜åŒ–
   * - å†…å­˜ä½¿ç”¨æ§åˆ¶
   * - ç®—æ³•å¤æ‚åº¦ä¼˜åŒ–
   */
  extractWords(text: string, options?: {
    includeStopWords?: boolean
    minLength?: number
    includePositions?: boolean
  }): string[] | WordInfo[] {
    const {
      includeStopWords = false,
      minLength = 1,
      includePositions = false
    } = options || {}

    const cacheKey = `words_${text.slice(0, 100)}_${includeStopWords}_${minLength}_${includePositions}`
    
    if (this.cache.has(cacheKey)) {
      return this.cache.get(cacheKey)
    }

    // Basic text cleaning
    const cleanText = this.cleanText(text)
    const sentences = this.splitIntoSentences(cleanText)
    
    const result: (string | WordInfo)[] = []
    let globalPosition = 0

    sentences.forEach((sentence, sentenceIndex) => {
      const words = sentence.split(EXTRA_WHITESPACE).filter(Boolean)
      
      words.forEach((word, wordIndex) => {
        const cleanWord = this.cleanWord(word)
        
        if (this.isValidWord(cleanWord, minLength, includeStopWords)) {
          if (includePositions) {
            result.push({
              word: cleanWord.toLowerCase(),
              position: globalPosition + wordIndex,
              sentence: sentenceIndex,
              context: this.getWordContext(sentence, wordIndex, 3)
            })
          } else {
            result.push(cleanWord.toLowerCase())
          }
        }
      })
      
      globalPosition += words.length
    })

    this.cache.set(cacheKey, result)
    return result
  }

  /**
   * ğŸ“„ æå–å¥å­å¹¶ç”Ÿæˆå…ƒæ•°æ®
   * 
   * @param text - è¾“å…¥æ–‡æœ¬å†…å®¹
   * @returns SentenceInfo[] - å¥å­ä¿¡æ¯æ•°ç»„
   * 
   * ğŸ“‹ åˆ†æç»´åº¦:
   * - å¥å­æ–‡æœ¬å†…å®¹
   * - åŒ…å«è¯æ±‡åˆ—è¡¨
   * - å¥å­ä½ç½®ç´¢å¼•
   * - è¯æ±‡æ•°é‡ç»Ÿè®¡
   * 
   * ğŸ¯ åº”ç”¨åœºæ™¯:
   * - æ–‡æœ¬ç»“æ„åˆ†æ
   * - å¥å­å¤æ‚åº¦è¯„ä¼°
   * - è¯­è¨€å­¦ä¹ è¾…åŠ©
   * - é˜…è¯»éš¾åº¦è¯„çº§
   * 
   * ğŸ›¡ï¸ å¤„ç†ä¿éšœ:
   * - å¥å­è¾¹ç•Œå‡†ç¡®æ£€æµ‹
   * - è¯æ±‡æ ‡å‡†åŒ–å¤„ç†
   * - ç©ºå¥å­è¿‡æ»¤
   * - æ•°æ®å®Œæ•´æ€§éªŒè¯
   */
  extractSentences(text: string): SentenceInfo[] {
    const cleanText = this.cleanText(text)
    const sentences = this.splitIntoSentences(cleanText)
    
    return sentences.map((sentence, index) => {
      const words = sentence.split(EXTRA_WHITESPACE).filter(Boolean)
      
      return {
        text: sentence.trim(),
        words: words.map(w => this.cleanWord(w).toLowerCase()),
        position: index,
        length: words.length
      }
    })
  }

  /**
   * ğŸ“Š åˆ†ææ–‡æœ¬å¤æ‚åº¦å’Œå¯è¯»æ€§
   * 
   * @param text - å¾…åˆ†ææ–‡æœ¬
   * @returns å¤æ‚åº¦åˆ†æç»“æœå¯¹è±¡
   * 
   * ğŸ“‹ åˆ†ææŒ‡æ ‡:
   * - readabilityScore: Fleschå¯è¯»æ€§è¯„åˆ†
   * - averageWordsPerSentence: å¹³å‡å¥é•¿
   * - averageSyllablesPerWord: å¹³å‡éŸ³èŠ‚æ•°
   * - complexWordCount: å¤æ‚è¯æ±‡æ•°é‡
   * - sentenceCount: å¥å­æ€»æ•°
   * - wordCount: è¯æ±‡æ€»æ•°
   * - characterCount: å­—ç¬¦æ€»æ•°
   * - difficulty: éš¾åº¦ç­‰çº§è¯„ä¼°
   * 
   * ğŸ¯ ç®—æ³•åŸºç¡€:
   * - Flesch Reading Easeå…¬å¼
   * - éŸ³èŠ‚è®¡æ•°å¯å‘å¼ç®—æ³•
   * - ç»Ÿè®¡å­¦åˆ†ææ–¹æ³•
   * - ç»éªŒé˜ˆå€¼åˆ¤æ–­
   * 
   * ğŸ›¡ï¸ æ•°æ®å¯é æ€§:
   * - é™¤é›¶é”™è¯¯é˜²æŠ¤
   * - è¾¹ç•Œå€¼å¤„ç†
   * - å¼‚å¸¸æ•°æ®è¿‡æ»¤
   * - ç»“æœåˆç†æ€§éªŒè¯
   * 
   * âš™ï¸ æ€§èƒ½è€ƒè™‘:
   * - å•æ¬¡éå†ä¼˜åŒ–
   * - ç¼“å­˜ä¸­é—´ç»“æœ
   * - ç®—æ³•å¤æ‚åº¦æ§åˆ¶
   * - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
   */
  analyzeComplexity(text: string): {
    readabilityScore: number
    averageWordsPerSentence: number
    averageSyllablesPerWord: number
    complexWordCount: number
    sentenceCount: number
    wordCount: number
    characterCount: number
    difficulty: 'easy' | 'medium' | 'hard'
  } {
    const sentences = this.extractSentences(text)
    const words = this.extractWords(text) as string[]
    
    const sentenceCount = sentences.length
    const wordCount = words.length
    const characterCount = text.replace(/\s+/g, '').length
    
    const averageWordsPerSentence = wordCount / Math.max(sentenceCount, 1)
    
    // Calculate average syllables per word
    const syllableCounts = words.map(word => this.countSyllables(word))
    const averageSyllablesPerWord = syllableCounts.reduce((a, b) => a + b, 0) / Math.max(wordCount, 1)
    
    // Count complex words (3+ syllables)
    const complexWordCount = syllableCounts.filter(count => count >= 3).length
    
    // Flesch Reading Ease Score
    const readabilityScore = 206.835 - 
      (1.015 * averageWordsPerSentence) - 
      (84.6 * averageSyllablesPerWord)
    
    // Determine difficulty
    let difficulty: 'easy' | 'medium' | 'hard'
    if (readabilityScore >= 70) difficulty = 'easy'
    else if (readabilityScore >= 50) difficulty = 'medium'
    else difficulty = 'hard'

    return {
      readabilityScore: Math.max(0, Math.min(100, readabilityScore)),
      averageWordsPerSentence,
      averageSyllablesPerWord,
      complexWordCount,
      sentenceCount,
      wordCount,
      characterCount,
      difficulty
    }
  }

  /**
   * ğŸ”— æŸ¥æ‰¾è¯æ±‡æ­é…å…³ç³»
   * 
   * @param text - æ–‡æœ¬å†…å®¹
   * @param targetWord - ç›®æ ‡è¯æ±‡
   * @param windowSize - æ­é…çª—å£å¤§å°
   * @returns æ­é…è¯æ±‡åˆ†æç»“æœ
   * 
   * ğŸ“‹ æ­é…åˆ†æ:
   * - word: æ­é…è¯æ±‡
   * - frequency: å…±ç°é¢‘ç‡
   * - distance: å¹³å‡è·ç¦»
   * 
   * ğŸ¯ ç®—æ³•ç‰¹ç‚¹:
   * - æ»‘åŠ¨çª—å£ç®—æ³•
   * - ç»Ÿè®¡å­¦å…±ç°åˆ†æ
   * - è·ç¦»æƒé‡è®¡ç®—
   * - é¢‘ç‡æ’åºä¼˜åŒ–
   * 
   * ğŸ›¡ï¸ è´¨é‡ä¿è¯:
   * - åœç”¨è¯è¿‡æ»¤
   * - ç›®æ ‡è¯æ’é™¤
   * - æœ€å°é¢‘ç‡é˜ˆå€¼
   * - ç»“æœæ•°é‡é™åˆ¶
   * 
   * âš™ï¸ æ€§èƒ½ä¼˜åŒ–:
   * - é«˜æ•ˆçš„çª—å£æ‰«æ
   * - Mapæ•°æ®ç»“æ„ç»Ÿè®¡
   * - å•æ¬¡éå†ç®—æ³•
   * - å†…å­˜ä½¿ç”¨æ§åˆ¶
   */
  findCollocations(text: string, targetWord: string, windowSize: number = 5): {
    word: string
    frequency: number
    distance: number
  }[] {
    const words = this.extractWords(text) as string[]
    const targetIndex = words.indexOf(targetWord.toLowerCase())
    
    if (targetIndex === -1) return []
    
    const collocations = new Map<string, { count: number; totalDistance: number }>()
    
    // Find all occurrences of target word
    words.forEach((word, index) => {
      if (word === targetWord.toLowerCase()) {
        // Look for words within the window
        for (let i = Math.max(0, index - windowSize); 
             i <= Math.min(words.length - 1, index + windowSize); 
             i++) {
          
          if (i !== index && !STOP_WORDS.has(words[i])) {
            const collocate = words[i]
            const distance = Math.abs(i - index)
            
            if (!collocations.has(collocate)) {
              collocations.set(collocate, { count: 0, totalDistance: 0 })
            }
            
            const entry = collocations.get(collocate)!
            entry.count++
            entry.totalDistance += distance
          }
        }
      }
    })
    
    // Convert to array and sort by frequency
    return Array.from(collocations.entries())
      .map(([word, data]) => ({
        word,
        frequency: data.count,
        distance: data.totalDistance / data.count
      }))
      .sort((a, b) => b.frequency - a.frequency)
      .slice(0, 20)
  }

  /**
   * ğŸ“ æå–Nå…ƒè¯­æ³•æ¨¡å¼
   * 
   * @param text - æ–‡æœ¬å†…å®¹
   * @param n - Nå…ƒè¯­æ³•é•¿åº¦
   * @returns Nå…ƒè¯­æ³•åˆ†æç»“æœ
   * 
   * ğŸ“‹ Nå…ƒè¯­æ³•ç±»å‹:
   * - n=1: å•è¯(unigram)
   * - n=2: åŒè¯(bigram)
   * - n=3: ä¸‰è¯(trigram)
   * - n>3: å¤šè¯çŸ­è¯­
   * 
   * ğŸ¯ åº”ç”¨ä»·å€¼:
   * - çŸ­è¯­æ¨¡å¼è¯†åˆ«
   * - è¯­è¨€æ¨¡å‹æ„å»º
   * - ç¿»è¯‘è´¨é‡è¯„ä¼°
   * - å†™ä½œé£æ ¼åˆ†æ
   * 
   * ğŸ›¡ï¸ è´¨é‡æ§åˆ¶:
   * - æœ€å°é¢‘ç‡è¿‡æ»¤
   * - åœç”¨è¯æ•æ„Ÿå¤„ç†
   * - é•¿åº¦åˆç†æ€§æ£€æŸ¥
   * - ç»“æœæ•°é‡é™åˆ¶
   * 
   * âš™ï¸ ç®—æ³•æ•ˆç‡:
   * - æ»‘åŠ¨çª—å£æå–
   * - Mapæ•°æ®ç»“æ„ç»Ÿè®¡
   * - é¢‘ç‡æ’åºä¼˜åŒ–
   * - å†…å­˜ä½¿ç”¨æ§åˆ¶
   */
  extractNGrams(text: string, n: number = 2): { phrase: string; frequency: number }[] {
    const words = this.extractWords(text, { includeStopWords: true }) as string[]
    const ngrams = new Map<string, number>()
    
    for (let i = 0; i <= words.length - n; i++) {
      const ngram = words.slice(i, i + n).join(' ')
      ngrams.set(ngram, (ngrams.get(ngram) || 0) + 1)
    }
    
    return Array.from(ngrams.entries())
      .map(([phrase, frequency]) => ({ phrase, frequency }))
      .filter(item => item.frequency > 1) // Only keep phrases that appear more than once
      .sort((a, b) => b.frequency - a.frequency)
      .slice(0, 50)
  }

  /**
   * ğŸ”‘ ä½¿ç”¨TF-IDFç®—æ³•æå–å…³é”®è¯
   * 
   * @param text - æ–‡æœ¬å†…å®¹
   * @param maxKeywords - æœ€å¤§å…³é”®è¯æ•°é‡
   * @returns å…³é”®è¯åˆ†æç»“æœ
   * 
   * ğŸ“‹ TF-IDFç®—æ³•:
   * - TF: è¯é¢‘(Term Frequency)
   * - IDF: é€†æ–‡æ¡£é¢‘ç‡(Inverse Document Frequency)
   * - Score: TF Ã— IDFç»¼åˆè¯„åˆ†
   * 
   * ğŸ¯ è¯„åˆ†ç­–ç•¥:
   * - é¢‘ç‡é‡è¦æ€§æƒé‡
   * - è¯æ±‡é•¿åº¦åŠ æƒ
   * - ç¨€æœ‰åº¦ä»·å€¼è¯„ä¼°
   * - ç»¼åˆé‡è¦æ€§æ’åº
   * 
   * ğŸ›¡ï¸ è´¨é‡ä¿è¯:
   * - åœç”¨è¯è¿‡æ»¤
   * - æœ€å°é¢‘ç‡é˜ˆå€¼
   * - è¯æ±‡é•¿åº¦é™åˆ¶
   * - ç»“æœæ•°é‡æ§åˆ¶
   * 
   * âš™ï¸ ç®—æ³•ä¼˜åŒ–:
   * - å•æ¬¡éå†ç»Ÿè®¡
   * - æ•°å­¦å…¬å¼ä¼˜åŒ–
   * - æ’åºç®—æ³•é«˜æ•ˆ
   * - å†…å­˜ä½¿ç”¨èŠ‚çº¦
   */
  extractKeywords(text: string, maxKeywords: number = 20): {
    word: string
    score: number
    frequency: number
  }[] {
    const words = this.extractWords(text) as string[]
    const wordFreq = new Map<string, number>()
    
    // Count word frequencies
    words.forEach(word => {
      wordFreq.set(word, (wordFreq.get(word) || 0) + 1)
    })
    
    // Calculate scores (simplified TF-IDF)
    const totalWords = words.length
    const keywords = Array.from(wordFreq.entries())
      .map(([word, freq]) => {
        // Term frequency
        const tf = freq / totalWords
        
        // Inverse document frequency (simplified - using word length and frequency)
        const idf = Math.log(totalWords / freq) + word.length * 0.1
        
        return {
          word,
          score: tf * idf,
          frequency: freq
        }
      })
      .filter(item => item.frequency > 1) // Filter rare words
      .sort((a, b) => b.score - a.score)
      .slice(0, maxKeywords)
    
    return keywords
  }

  /**
   * ğŸ’­ åˆ†ææ–‡æœ¬æƒ…æ„Ÿå€¾å‘
   * 
   * @param text - æ–‡æœ¬å†…å®¹
   * @returns æƒ…æ„Ÿåˆ†æç»“æœ
   * 
   * ğŸ“‹ åˆ†æç»“æœ:
   * - score: æƒ…æ„Ÿè¯„åˆ†(-1åˆ°1)
   * - magnitude: æƒ…æ„Ÿå¼ºåº¦(0åˆ°1)
   * - label: æƒ…æ„Ÿæ ‡ç­¾(positive/negative/neutral)
   * 
   * ğŸ¯ ç®—æ³•åŸºç¡€:
   * - è¯å…¸åŒ¹é…æ–¹æ³•
   * - ç®€å•åŠ æƒè®¡ç®—
   * - é˜ˆå€¼åˆ†ç±»åˆ¤æ–­
   * - ç»Ÿè®¡å­¦å½’ä¸€åŒ–
   * 
   * ğŸ›¡ï¸ ç®—æ³•é™åˆ¶:
   * - ç®€åŒ–ç‰ˆå®ç°
   * - è‹±è¯­æƒ…æ„Ÿè¯å…¸
   * - ä¸Šä¸‹æ–‡ä¸æ•æ„Ÿ
   * - åŸºç¡€å‡†ç¡®åº¦
   * 
   * âš™ï¸ æ‰©å±•æ–¹å‘:
   * - æœºå™¨å­¦ä¹ æ¨¡å‹
   * - æ·±åº¦å­¦ä¹ ç®—æ³•
   * - å¤šè¯­è¨€æ”¯æŒ
   * - ä¸Šä¸‹æ–‡ç†è§£
   */
  analyzeSentiment(text: string): {
    score: number
    magnitude: number
    label: 'positive' | 'negative' | 'neutral'
  } {
    // Simple word-based sentiment analysis
    const positiveWords = new Set([
      'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'awesome',
      'beautiful', 'love', 'like', 'enjoy', 'happy', 'pleased', 'satisfied',
      'successful', 'effective', 'efficient', 'beneficial', 'valuable', 'useful'
    ])
    
    const negativeWords = new Set([
      'bad', 'terrible', 'awful', 'horrible', 'disappointing', 'frustrating',
      'difficult', 'hard', 'challenging', 'problem', 'issue', 'error', 'fail',
      'wrong', 'poor', 'weak', 'limited', 'insufficient', 'inadequate'
    ])
    
    const words = this.extractWords(text) as string[]
    let positiveCount = 0
    let negativeCount = 0
    
    words.forEach(word => {
      if (positiveWords.has(word)) positiveCount++
      if (negativeWords.has(word)) negativeCount++
    })
    
    const totalSentimentWords = positiveCount + negativeCount
    const score = totalSentimentWords === 0 
      ? 0 
      : (positiveCount - negativeCount) / totalSentimentWords
    
    const magnitude = totalSentimentWords / words.length
    
    let label: 'positive' | 'negative' | 'neutral'
    if (score > 0.1) label = 'positive'
    else if (score < -0.1) label = 'negative'
    else label = 'neutral'
    
    return { score, magnitude, label }
  }

  /**
   * ğŸ“Š è·å–æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
   * 
   * @param text - æ–‡æœ¬å†…å®¹
   * @returns ç»Ÿè®¡ä¿¡æ¯å¯¹è±¡
   * 
   * ğŸ“‹ ç»Ÿè®¡ç»´åº¦:
   * - characters: æ€»å­—ç¬¦æ•°
   * - charactersNoSpaces: éç©ºæ ¼å­—ç¬¦æ•°
   * - words: è¯æ±‡æ€»æ•°
   * - sentences: å¥å­æ€»æ•°
   * - paragraphs: æ®µè½æ€»æ•°
   * - averageWordsPerSentence: å¹³å‡å¥é•¿
   * - averageCharactersPerWord: å¹³å‡è¯é•¿
   * - readingTimeMinutes: é¢„ä¼°é˜…è¯»æ—¶é—´
   * 
   * ğŸ¯ åº”ç”¨åœºæ™¯:
   * - å†…å®¹è´¨é‡è¯„ä¼°
   * - é˜…è¯»éš¾åº¦åˆ†æ
   * - ç¼–è¾‘è¾…åŠ©å·¥å…·
   * - å­¦ä¹ è¿›åº¦è·Ÿè¸ª
   * 
   * ğŸ›¡ï¸ è®¡ç®—ä¿éšœ:
   * - é™¤é›¶é”™è¯¯é˜²æŠ¤
   * - è´Ÿå€¼ç»“æœé˜²æŠ¤
   * - è¾¹ç•Œæƒ…å†µå¤„ç†
   * - æ•°æ®åˆç†æ€§éªŒè¯
   * 
   * âš™ï¸ ç®—æ³•æ•ˆç‡:
   * - å•æ¬¡éå†è®¡ç®—
   * - ç¼“å­˜ä¸­é—´ç»“æœ
   * - ç®€å•æ•°å­¦è¿ç®—
   * - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
   */
  getStatistics(text: string): {
    characters: number
    charactersNoSpaces: number
    words: number
    sentences: number
    paragraphs: number
    averageWordsPerSentence: number
    averageCharactersPerWord: number
    readingTimeMinutes: number
  } {
    const characters = text.length
    const charactersNoSpaces = text.replace(/\s/g, '').length
    const words = this.extractWords(text).length
    const sentences = this.extractSentences(text).length
    const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim()).length
    
    const averageWordsPerSentence = sentences > 0 ? words / sentences : 0
    const averageCharactersPerWord = words > 0 ? charactersNoSpaces / words : 0
    const readingTimeMinutes = words / 200 // Assuming 200 words per minute
    
    return {
      characters,
      charactersNoSpaces,
      words,
      sentences,
      paragraphs,
      averageWordsPerSentence,
      averageCharactersPerWord,
      readingTimeMinutes
    }
  }

  /**
   * ğŸ§¹ æ–‡æœ¬æ¸…ç†å’Œæ ‡å‡†åŒ–
   * 
   * @param text - åŸå§‹æ–‡æœ¬
   * @returns string - æ¸…ç†åæ–‡æœ¬
   * 
   * ğŸ“‹ æ¸…ç†æ­¥éª¤:
   * - è¡Œç»“æŸç¬¦æ ‡å‡†åŒ–
   * - åˆ¶è¡¨ç¬¦è½¬æ¢ç©ºæ ¼
   * - æ ‡ç‚¹ç¬¦å·ç§»é™¤
   * - å¤šä½™ç©ºæ ¼å‹ç¼©
   * - é¦–å°¾ç©ºæ ¼ç§»é™¤
   * 
   * ğŸ¯ æ ‡å‡†åŒ–ç›®æ ‡:
   * - ç»Ÿä¸€æ–‡æœ¬æ ¼å¼
   * - ç®€åŒ–åç»­å¤„ç†
   * - æé«˜åˆ†æå‡†ç¡®æ€§
   * - ä¼˜åŒ–ç®—æ³•æ€§èƒ½
   * 
   * ğŸ›¡ï¸ ä¿æŠ¤æœºåˆ¶:
   * - ä¿ç•™æ’‡å·å­—ç¬¦
   * - ä¿æŒåŸºæœ¬ç»“æ„
   * - é¿å…è¿‡åº¦æ¸…ç†
   * - ç»´æŠ¤å¯è¯»æ€§
   */
  private cleanText(text: string): string {
    return text
      .replace(/\r\n/g, '\n') // Normalize line endings
      .replace(/\t/g, ' ') // Replace tabs with spaces
      .replace(PUNCTUATION, ' ') // Remove punctuation (keep apostrophes)
      .replace(EXTRA_WHITESPACE, ' ') // Normalize whitespace
      .trim()
  }

  /**
   * ğŸ§¹ å•è¯æ¸…ç†å’Œæ ‡å‡†åŒ–
   * 
   * @param word - åŸå§‹å•è¯
   * @returns string - æ¸…ç†åå•è¯
   * 
   * ğŸ“‹ æ¸…ç†è§„åˆ™:
   * - ç§»é™¤é¦–å°¾å¼•å·
   * - ç§»é™¤æœ«å°¾æ ‡ç‚¹
   * - ä¿ç•™å†…éƒ¨æ’‡å·
   * - ç©ºæ ¼ä¿®å‰ªå¤„ç†
   * 
   * ğŸ¯ æ¸…ç†ç›®æ ‡:
   * - è·å¾—çº¯å‡€è¯æ±‡
   * - ä¿æŒè¯æ±‡å®Œæ•´æ€§
   * - ç»Ÿä¸€æ ¼å¼æ ‡å‡†
   * - æé«˜åŒ¹é…å‡†ç¡®æ€§
   */
  private cleanWord(word: string): string {
    return word
      .replace(/^['"]|['"]$/g, '') // Remove leading/trailing quotes
      .replace(/[.,;:!?]$/g, '') // Remove trailing punctuation
      .trim()
  }

  /**
   * âœ… è¯æ±‡æœ‰æ•ˆæ€§éªŒè¯
   * 
   * @param word - å¾…éªŒè¯è¯æ±‡
   * @param minLength - æœ€å°é•¿åº¦
   * @param includeStopWords - æ˜¯å¦åŒ…å«åœç”¨è¯
   * @returns boolean - æ˜¯å¦æœ‰æ•ˆ
   * 
   * ğŸ“‹ éªŒè¯è§„åˆ™:
   * - æœ€å°é•¿åº¦æ£€æŸ¥
   * - ç¼©å†™è¯è¿‡æ»¤
   * - æ ¼å¼æœ‰æ•ˆæ€§éªŒè¯
   * - åœç”¨è¯è¿‡æ»¤
   * 
   * ğŸ¯ è´¨é‡ä¿è¯:
   * - ç¡®ä¿è¯æ±‡è´¨é‡
   * - è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡
   * - æé«˜åˆ†æå‡†ç¡®æ€§
   * - ä¼˜åŒ–å¤„ç†æ•ˆç‡
   */
  private isValidWord(word: string, minLength: number, includeStopWords: boolean): boolean {
    if (word.length < minLength) return false
    if (CONTRACTION.test(word)) return false
    if (!VALID_WORD.test(word) && !HYPHENATED.test(word)) return false
    if (!includeStopWords && STOP_WORDS.has(word.toLowerCase())) return false
    
    return true
  }

  /**
   * ğŸ“„ å¥å­è¾¹ç•Œæ£€æµ‹åˆ†å‰²
   * 
   * @param text - è¾“å…¥æ–‡æœ¬
   * @returns string[] - å¥å­æ•°ç»„
   * 
   * ğŸ“‹ åˆ†å‰²è§„åˆ™:
   * - å¥æœ«æ ‡ç‚¹ç¬¦å·è¯†åˆ«
   * - ç©ºå¥å­è¿‡æ»¤
   * - ç©ºæ ¼ä¿®å‰ªå¤„ç†
   * - ç®€å•è¾¹ç•Œæ£€æµ‹
   * 
   * ğŸ›¡ï¸ ç®—æ³•é™åˆ¶:
   * - ç®€åŒ–ç‰ˆå®ç°
   * - ä¸å¤„ç†ç¼©å†™
   * - ä¸å¤„ç†å¤æ‚è¾¹ç•Œ
   * - åŸºç¡€å‡†ç¡®åº¦
   * 
   * âš™ï¸ æ”¹è¿›æ–¹å‘:
   * - æœºå™¨å­¦ä¹ æ¨¡å‹
   * - è§„åˆ™å¼•æ“å®Œå–„
   * - ä¸Šä¸‹æ–‡ç†è§£
   * - å¤šè¯­è¨€æ”¯æŒ
   */
  private splitIntoSentences(text: string): string[] {
    // Simple sentence splitting - can be improved with more sophisticated rules
    return text
      .split(/[.!?]+/)
      .map(sentence => sentence.trim())
      .filter(sentence => sentence.length > 0)
  }

  /**
   * ğŸ” è·å–è¯æ±‡ä¸Šä¸‹æ–‡ç¯å¢ƒ
   * 
   * @param sentence - æ‰€åœ¨å¥å­
   * @param wordIndex - è¯æ±‡ä½ç½®
   * @param windowSize - ä¸Šä¸‹æ–‡çª—å£
   * @returns string - ä¸Šä¸‹æ–‡æ–‡æœ¬
   * 
   * ğŸ“‹ æå–é€»è¾‘:
   * - ç¡®å®šçª—å£è¾¹ç•Œ
   * - æå–ç›¸é‚»è¯æ±‡
   * - æ‹¼æ¥ä¸Šä¸‹æ–‡
   * - è¿”å›å®Œæ•´ç‰‡æ®µ
   * 
   * ğŸ¯ åº”ç”¨ä»·å€¼:
   * - æä¾›è¯æ±‡è¯­å¢ƒ
   * - è¾…åŠ©è¯­ä¹‰ç†è§£
   * - æ”¯æŒå­¦ä¹ åŠŸèƒ½
   * - å¢å¼ºç”¨æˆ·ä½“éªŒ
   */
  private getWordContext(sentence: string, wordIndex: number, windowSize: number): string {
    const words = sentence.split(/\s+/)
    const start = Math.max(0, wordIndex - windowSize)
    const end = Math.min(words.length, wordIndex + windowSize + 1)
    
    return words.slice(start, end).join(' ')
  }

  /**
   * ğŸ”¢ éŸ³èŠ‚æ•°é‡è®¡ç®—
   * 
   * @param word - ç›®æ ‡è¯æ±‡
   * @returns number - éŸ³èŠ‚æ•°é‡
   * 
   * ğŸ“‹ è®¡ç®—è§„åˆ™:
   * - çŸ­è¯æ±‡é»˜è®¤1éŸ³èŠ‚
   * - å°¾éƒ¨eå­—æ¯ç§»é™¤
   * - å…ƒéŸ³ç»„åˆè®¡æ•°
   * - æœ€å°å€¼ä¿æŠ¤
   * 
   * ğŸ›¡ï¸ ç®—æ³•é™åˆ¶:
   * - å¯å‘å¼è§„åˆ™
   * - è‹±è¯­ä¸“ç”¨
   * - è¿‘ä¼¼è®¡ç®—
   * - åŸºç¡€å‡†ç¡®åº¦
   * 
   * âš™ï¸ æ”¹è¿›æ–¹å‘:
   * - è¯­éŸ³å­¦è¯å…¸
   * - æœºå™¨å­¦ä¹ æ¨¡å‹
   * - å¤šè¯­è¨€æ”¯æŒ
   * - ç²¾ç¡®éŸ³èŠ‚æ£€æµ‹
   */
  private countSyllables(word: string): number {
    if (word.length <= 3) return 1
    
    word = word.toLowerCase()
    
    // Remove trailing e
    if (word.endsWith('e')) {
      word = word.slice(0, -1)
    }
    
    // Count vowel groups
    const vowelGroups = word.match(/[aeiouy]+/g)
    return vowelGroups ? vowelGroups.length : 1
  }

  /**
   * ğŸ—‘ï¸ æ¸…ç©ºå†…éƒ¨ç¼“å­˜
   * 
   * ğŸ“‹ æ¸…ç†èŒƒå›´:
   * - æ‰€æœ‰ç¼“å­˜æ•°æ®
   * - å†…å­˜å ç”¨é‡Šæ”¾
   * - çŠ¶æ€é‡ç½®å®Œæˆ
   * - æ€§èƒ½å½±å“æ¶ˆé™¤
   * 
   * ğŸ¯ ä½¿ç”¨åœºæ™¯:
   * - å†…å­˜ä¼˜åŒ–éœ€æ±‚
   * - æ•°æ®æ›´æ–°åæ¸…ç†
   * - æµ‹è¯•ç¯å¢ƒé‡ç½®
   * - é•¿æ—¶é—´è¿è¡Œç»´æŠ¤
   */
  clearCache(): void {
    this.cache.clear()
  }

  /**
   * ğŸ“Š è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
   * 
   * @returns ç¼“å­˜ç»Ÿè®¡å¯¹è±¡
   * 
   * ğŸ“‹ ç»Ÿè®¡ä¿¡æ¯:
   * - size: ç¼“å­˜æ¡ç›®æ•°é‡
   * - keys: ç¼“å­˜é”®ååˆ—è¡¨
   * 
   * ğŸ¯ ç”¨é€”åœºæ™¯:
   * - æ€§èƒ½è°ƒè¯•åˆ†æ
   * - å†…å­˜ä½¿ç”¨ç›‘æ§
   * - ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
   * - ç³»ç»Ÿå¥åº·æ£€æŸ¥
   */
  getCacheStats(): { size: number; keys: string[] } {
    return {
      size: this.cache.size,
      keys: Array.from(this.cache.keys())
    }
  }
}

/**
 * ğŸ­ æ–‡æœ¬åˆ†æå™¨å•ä¾‹å®ä¾‹
 * 
 * ğŸ“‹ å•ä¾‹ä¼˜åŠ¿:
 * - å…¨å±€çŠ¶æ€ä¸€è‡´æ€§
 * - ç¼“å­˜æ•°æ®å…±äº«
 * - èµ„æºä½¿ç”¨ä¼˜åŒ–
 * - é…ç½®ç»Ÿä¸€ç®¡ç†
 * 
 * ğŸ¯ ä½¿ç”¨æ–¹å¼:
 * - ç›´æ¥å¯¼å…¥ä½¿ç”¨
 * - æ–¹æ³•è°ƒç”¨è®¿é—®
 * - ç¼“å­˜è‡ªåŠ¨ç®¡ç†
 * - æ€§èƒ½è‡ªåŠ¨ä¼˜åŒ–
 */
export const textAnalyzer = new TextAnalyzer()

/**
 * ğŸ” åœç”¨è¯æ£€æŸ¥å·¥å…·å‡½æ•°
 * 
 * @param word - å¾…æ£€æŸ¥è¯æ±‡
 * @returns boolean - æ˜¯å¦ä¸ºåœç”¨è¯
 * 
 * ğŸ“‹ æ£€æŸ¥é€»è¾‘:
 * - å¤§å°å†™æ ‡å‡†åŒ–
 * - åœç”¨è¯é›†åˆæŸ¥æ‰¾
 * - å¸ƒå°”å€¼ç»“æœè¿”å›
 * - é«˜æ•ˆæŸ¥æ‰¾ç®—æ³•
 */
export function isStopWord(word: string): boolean {
  return STOP_WORDS.has(word.toLowerCase())
}

/**
 * ğŸ§¹ æ–‡æœ¬æ¸…ç†å·¥å…·å‡½æ•°
 * 
 * @param text - åŸå§‹æ–‡æœ¬
 * @returns string - æ¸…ç†åæ–‡æœ¬
 * 
 * ğŸ“‹ æ¸…ç†æ–¹å¼:
 * - è¯æ±‡æå–æ ‡å‡†åŒ–
 * - ç©ºæ ¼è¿æ¥é‡ç»„
 * - åœç”¨è¯ä¿ç•™
 * - æ ¼å¼ç»Ÿä¸€å¤„ç†
 */
export function cleanText(text: string): string {
  return new TextAnalyzer().extractWords(text).join(' ')
}

/**
 * ğŸ“Š è¯æ±‡å¯†åº¦è®¡ç®—å·¥å…·å‡½æ•°
 * 
 * @param text - æ–‡æœ¬å†…å®¹
 * @param targetWord - ç›®æ ‡è¯æ±‡
 * @returns number - è¯æ±‡å¯†åº¦
 * 
 * ğŸ“‹ è®¡ç®—å…¬å¼:
 * - ç›®æ ‡è¯æ±‡å‡ºç°æ¬¡æ•°
 * - æ€»è¯æ±‡æ•°é‡ç»Ÿè®¡
 * - å¯†åº¦æ¯”å€¼è®¡ç®—
 * - å°æ•°ç»“æœè¿”å›
 * 
 * ğŸ¯ åº”ç”¨ä»·å€¼:
 * - å…³é”®è¯é‡è¦æ€§è¯„ä¼°
 * - æ–‡æœ¬ä¸»é¢˜åˆ†æ
 * - SEOä¼˜åŒ–æŒ‡å¯¼
 * - å†…å®¹è´¨é‡è¯„ä»·
 */
export function getWordDensity(text: string, targetWord: string): number {
  const words = new TextAnalyzer().extractWords(text, { includeStopWords: true }) as string[]
  const occurrences = words.filter(word => word === targetWord.toLowerCase()).length
  return occurrences / words.length
}